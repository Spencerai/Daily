# Daily 何红亮每日学习“日记”  2019

    这是何红亮同学保存每日记录的地方，GitHub上的第一个目录。</p>
    在这里，我将记录每天自己看到的有收获的文章。比如：数据挖掘、机器学习、深度学习、NLP、数据竞赛、Python进阶及有关数据及建模方面内容。
    在数据科学的道路上，能够慢慢进步和成长！坚持每天进步一点点！</p>
    如有小伙伴愿意在数据道路上结伴而行，可以关注微信公众号《通往数据自由之路》在后台留言。
    <br>Keywords: data mining  machine learning  deep learning（数据挖掘，机器学习，深度学习，自然语言处理 NLP）
----
<br>

以下是2019年目录！<br>



20190309:<br>
ThunderGBM：快成一道闪电的梯度提升决策树
>https://mp.weixin.qq.com/s?__biz=MzU1NTUxNTM0Mg==&mid=2247490516&idx=2&sn=df2b11c4ed994264d6e33b8f56cb1a36

20190308:<br>
用文本挖掘剖析近5万首《全唐诗》-- 一文学会NLP数种基础任务
>https://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&mid=2247486358&idx=1&sn=16b7646613d099472c54ba0f578aee68



20190307:<br>
解构BERT：从1亿个参数中提取6种模式
>https://mp.weixin.qq.com/s?__biz=MzU1MTkwNzIyOQ==&mid=2247487710&idx=1&sn=7ded81febf24846eb9b5d6bcb2a61bae


20190306:<br>
领域应用 | 从本体论开始说起——运营商关系图谱的构建及应用
>https://mp.weixin.qq.com/s?__biz=MzU2NjAxNDYwMg==&mid=2247485624&idx=1&sn=454cb3c533b7a84f029f0c6a8d7c1037


20190305:<br>
博士带你学LSTM|怎么开发一个LSTM模型来生成形状？(第十一章：开发生成LSTMs)
>https://mp.weixin.qq.com/s?__biz=MzU1MTkwNzIyOQ==&mid=2247487680&idx=1&sn=486cfdb7bc48ff26b9501c55545f6c6d



20190304:<br>
爬网页、洗数据、创建海量数据集一条龙！英伟达工程师小姐姐开源工具库（lazynlp）
>https://zhuanlan.zhihu.com/p/58128507

推荐系统召回四模型之：全能的FM模型
>https://zhuanlan.zhihu.com/p/58160982



20190303:<br>
万字长文概述NLP中的深度学习技术
>https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650757835&idx=2&sn=716ddb08d3abf2103da61799f9f11b73




20190302:<br>
自然语言处理基础：上下文词表征入门解读
>https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650757944&idx=4&sn=4bf1e7f7c479ee98b775ee195330e235





20190301:<br>
谷歌重磅开源NLP通用框架Lingvo，91位作者带来强悍功能
>https://zhuanlan.zhihu.com/p/57757850



20190228:<br>
各种NLP操作难实现？谷歌开源序列建模框架Lingvo
>https://zhuanlan.zhihu.com/p/57795395


20190227:<br>
Hulu背后的故事：NLP在Hulu的研究与实践
>https://mp.weixin.qq.com/s?__biz=MzU1NTMyOTI4Mw==&mid=2247488177&idx=1&sn=ce32c5e9eaf50c9d7f5f3f075d632fc3



20190226:<br>
「行知」Airbnb如何解决Embedding的数据稀疏问题？
>https://mp.weixin.qq.com/s?__biz=MzU1NTMyOTI4Mw==&mid=2247488210&idx=1&sn=306c9685520acb2e778ea9aa55969bea



20190225:<br>
自然语言处理怎么最快入门？
>https://www.zhihu.com/question/19895141/answer/515535069

赛尔笔记 | BiLSTM介绍及代码实现
>https://mp.weixin.qq.com/s?__biz=MzIxMjAzNDY5Mg==&mid=2650793399&idx=1&sn=f4a28d39d708e268b47abecd225b5178&scene=21#wechat_redirect





20190224:<br>
博士带你学LSTM|开发Encoder-Decoder LSTM模型的简单教程（附代码）
>https://mp.weixin.qq.com/s?__biz=MzU1MTkwNzIyOQ==&mid=2247487519&idx=1&sn=659666f65dcb79282b2e762f9f4fe804



20190223:<br>
一文看懂虚假新闻检测（附数据集 & 论文推荐）
>https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247495009&idx=1&sn=786d5297ba95117e72cb2e46a22d2935




20190222:<br>
深度学习不再是炼丹术！谷歌给出首个神经网络训练理论证明
>https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652038883&idx=1&sn=f6a471c31e9a6c461c71614027489423




20190221:<br>
WSDM Cup 2019自然语言推理任务获奖解题思路
>https://mp.weixin.qq.com/s/-ImgNNylBcU9tPxCP3pwbA



20190220:<br>
深度 | 强化学习应用金融投资组合优化（附代码）
>https://mp.weixin.qq.com/s?__biz=MzAxNTc0Mjg0Mg==&mid=2653290602&idx=1&sn=27ad2c311de6a8aa3ef0f66117fa1692

搞定NLP领域的“变形金刚”！手把手教你用BERT进行多标签文本分类
>https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651667790&idx=1&sn=c051c993ee561c7ada8c03b58679f305



20190219:<br>
PyTorch自然语言处理实战（附详细代码下载）
>https://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&mid=2247507380&idx=2&sn=00873527310eb9ff1197df2e12d3a9ec


20190218:<br>
自然语言处理怎么最快入门？（CodeWithZhangYi的回答）
>https://www.zhihu.com/question/19895141/answer/515535069




20190217:<br>
Byte Cup 2018国际机器学习竞赛夺冠记
>https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247494898&idx=1&sn=c38516d259c22c34e5341fa12858bd92

NLP中评价文本输出都有哪些方法？为什么要小心使用 BLEU？
>https://mp.weixin.qq.com/s?__biz=MzIzNjc0MTMwMA==&mid=2247487329&idx=1&sn=619f8fe0499ad8bccfcf4702863bc172




20190216:<br>
>放弃幻想，全面拥抱Transformer：自然语言处理三大特征抽取器（CNN/RNN/TF）比较

干货 | 自然语言处理中注意力机制综述
>https://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&mid=2247486207&idx=1&sn=ebb96535038c38667101efaf95dbbcdf




20190215:<br>
中文NLP福利！大规模中文自然语言处理语料
>https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652038359&idx=4&sn=63c4408011867983024c2c99a3490208

中文分词十年又回顾2007-2017--简报
>https://zhuanlan.zhihu.com/p/56107108




20190214:<br>
新年干货 | NLP一路走来的经验之谈（附重磅资源）
>https://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&mid=2247486226&idx=1&sn=26275decf4502433550ea2f1bb19507e




20190213:<br>
对话MSRA副院长周明：回望过去，展望未来，NLP有哪些发展趋势？
>https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650756950&idx=2&sn=f9d129bc2a86f2e6cd34c668b4d19c40



20190212:<br>
序列模型简介——RNN, Bidirectional RNN, LSTM, GRU
>https://mp.weixin.qq.com/s?__biz=MzI0NTE4NjA0OQ==&mid=2658359802&idx=1&sn=2edfa188927b7d783ac7d122619807f8


20190211:<br>
NLP - 基于 BERT 的中文命名实体识别（NER)
>https://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&mid=2650409148&idx=1&sn=19396b4adebb4387392b829ddd239c21

【干货】33页最新《自然语言处理中神经注意力机制综述》论文
>https://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&mid=2247507163&idx=1&sn=b89c1e8f004d138b93b025c5dcad43cf


20190210:<br>
斯坦福NLP团队发布最新自然语言处理Python库
>https://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&mid=2247507069&idx=2&sn=d9d6eef20516ef7622388c5d050e7877



20190209:<br>
FAIR&MIT提出知识蒸馏新方法：数据集蒸馏
>https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650756815&idx=4&sn=7161425a26ed2b23438382c6d2dcbcf4



20190208:<br>
对话清华NLP实验室刘知远：NLP搞事情少不了知识库与图神经网络
>https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650756797&idx=1&sn=b1914989c754315f6e5f8c29f3110bb4

20190207:<br>
MIT 深度学习基础教程：七个基本框架TensorFlow代码实战
>https://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&mid=2247506960&idx=1&sn=0e04b3f1cdc0bf8dbc9dd5bd25dc4022



20190206:<br>
读者喜欢看什么文章？腾讯微信融合时间过程与内容特征寻找答案
>https://mp.weixin.qq.com/s?__biz=MzU1NTUxNTM0Mg==&mid=2247490285&idx=1&sn=51b3a0cfdacf7bcba8e2233b9edb6e2d

20190205:<br>
论文浅尝 | 基于图注意力的常识对话生成
>https://mp.weixin.qq.com/s?__biz=MzU2NjAxNDYwMg==&mid=2247485496&idx=1&sn=d4249634586df5fd0acfe6b8d6f9c905


20190204:<br>
Click-Through Rate Prediction：银牌（Part2）
>https://mp.weixin.qq.com/s?__biz=MzU1Nzc1NjI0Nw==&mid=2247483914&idx=1&sn=b76d1e7df5e91aa75c2853943f0f21f2


20190203:<br>
AI所有领域最优论文+代码查找神器：966个ML任务、8500+论文任你选
>https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650756694&idx=1&sn=4d24091c015786a5321e8e8cb7691564

受限玻尔兹曼机原理及在推荐系统中的应用
>https://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&mid=2650409108&idx=1&sn=8ebc26251096997341496c492b6e2690



20190202:<br>
模型| 关于LSTM的种种探索
>https://mp.weixin.qq.com/s?__biz=Mzg3MDA3NTE1NQ==&mid=2247483816&idx=1&sn=fe1adda017bb0124ccc1d8e243331c00


20190201:<br>
命名实体识别（NER）综述
>https://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA==&mid=2650675122&idx=1&sn=a5041002769b48f70d0b0bdba2b8e96a


20190131:<br>
Word Embedding 词嵌入最新综述论文（附全文下载）
>https://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&mid=2247506729&idx=2&sn=5d26538d8b6a0aaccdf048a42a6cc28c


20190130:<br>
「回顾」基于金融智能风控的实时指标处理技术体系
>https://mp.weixin.qq.com/s?__biz=MzU1NTMyOTI4Mw==&mid=2247487658&idx=1&sn=b9dacc38bda9bfd2fa65e66810845dd9

20190129:<br>
香侬科技提出中文字型的深度学习模型Glyce，横扫13项中文NLP记录
>https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247494680&idx=1&sn=2574ebadc13f30bcb598cf5cbdf77c41



20190128:<br>
21种NLP任务激活函数大比拼：你一定猜不到谁赢了
>https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650756158&idx=2&sn=90cb49c49be078e7406539eb93561c9e




20190127:<br>
撩一发深度文本分类之RNN via Attention
>https://mp.weixin.qq.com/s?__biz=MzAxMzUzOTg3OQ==&mid=2455933904&idx=1&sn=07680beeefc8eb54dad3155a0ae4c766

“达观杯”文本智能处理挑战赛，季军带你飞
>https://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&mid=2650409084&idx=1&sn=d246f73c63bc749e05c241f44c967a4a




20190126:<br>
Facebook开源NLP迁移学习工具包，支持93种语言，性能最优
>https://mp.weixin.qq.com/s?__biz=MzU1NTUxNTM0Mg==&mid=2247490201&idx=1&sn=592539a7669c030d5b65863fe0665202

【官方】【中英】CS224n 斯坦福深度自然语言处理课 @雷锋字幕组
>https://www.bilibili.com/video/av41393758



20190125:<br>
AI Challenger 2018：细粒度用户评论情感分类冠军思路总结
>https://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&mid=2651750254&idx=2&sn=10cc4d29764cde39781fe79f0094b2cd

funNLP: 从文本中抽取结构化信息的超级资源包
>https://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&mid=2650409078&idx=1&sn=89e1fa01475343e244f8205debd5905b




20190124:<br>
如何到top5%？NLP文本分类和情感分析竞赛总结
>https://zhuanlan.zhihu.com/p/54397748



20190123:<br>
从KDD 2018最佳论文看Airbnb实时搜索排序中的Embedding技巧
>https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247494488&idx=1&sn=452ac80c593a9b31252031eac38d0e01





20190122:<br>
论坛报告|肖仰华教授：大数据时代的知识工程与知识管理
>https://mp.weixin.qq.com/s?__biz=MzI0MTI1Nzk1MA==&mid=2651677164&idx=1&sn=e92c982dba5b614862e02626aafbb42d

NLP 2018 Highlights
>https://mp.weixin.qq.com/s?__biz=MzU5NzI5MDgzOA==&mid=2247483977&idx=1&sn=7919b5a14bb4938fcfdcb806f7eb73de






20190121:<br>
ICLR2019少样本学习新思路：利用转导(Transductive)和标签传播
>https://zhuanlan.zhihu.com/p/55111343



20190120:<br>
免费自然语言处理(NLP)课程及教材分享
>https://mp.weixin.qq.com/s?__biz=MzIxNDgzNDg3NQ==&mid=2247485447&idx=1&sn=93deeaeb758c78af6a06e9d4efa79379



20190119:<br>
详解谷歌最强NLP模型BERT（理论+实战）
>https://mp.weixin.qq.com/s?__biz=MzU1NTUxNTM0Mg==&mid=2247490161&idx=3&sn=25c3b79f79bc7de573dabf695b7ce36f




20190118:<br>
赛尔原创 | 反讽识别综述
>https://zhuanlan.zhihu.com/p/55212330

文本分类实战--从TFIDF到深度学习（附代码）
>https://blog.csdn.net/liuchonge/article/details/72614524




20190117:<br>
大众点评搜索基于知识图谱的深度学习排序实践
>https://tech.meituan.com/2019/01/17/dianping-search-deeplearning.html




20190116:<br>
Attention mechanisms on NLP
>https://zhuanlan.zhihu.com/p/54491016


20190115:<br>
不只有BERT！盘点2018年NLP令人激动的10大想法
>https://zhuanlan.zhihu.com/p/53009094

NLP预训练模型大集合！
>https://zhuanlan.zhihu.com/p/53569058





20190114:<br>
以虎嗅网4W+文章的文本挖掘为例，展现数据分析的一整套流
